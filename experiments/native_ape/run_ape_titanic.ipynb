{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "from output_parsing.APE_to_notebook import parse_ape_solutions, solution_to_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "APE_PATH = Path('..') / '..' / 'APE' / 'APE-2.0.3-executable.jar'\n",
    "USE_CASE_PATH = Path('.').resolve() / 'usecases' / 'titanic'\n",
    "config = 'config_run.json'\n",
    "input_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"ontology_path\": \"../../ontology/ontology_v2_DIM_2.owl\",\n",
    "    \"ontologyPrefixIRI\": \"http://www.co-ode.org/ontologies/ont.owl#\",\n",
    "    \"toolsTaxonomyRoot\": \"ToolsTaxonomy\",\n",
    "    \"dataDimensionsTaxonomyRoots\": [\n",
    "        \"DataClass\",\n",
    "        \"StatisticalRelevance\"\n",
    "    ],\n",
    "    \"tool_annotations_path\": \"../../ontology/tool_annotations_v2_DIM_2.json\",\n",
    "    \"constraints_path\": \"constraints_run.json\",\n",
    "    \"solutions_dir_path\": \"./solutions/\",\n",
    "    \"solution_length\": {\n",
    "        \"min\": 2,\n",
    "        \"max\": 10\n",
    "    },\n",
    "    \"solutions\": \"5\",\n",
    "    \"timeout_sec\": \"1000\",\n",
    "    \"number_of_execution_scripts\": \"0\",\n",
    "    \"number_of_generated_graphs\": \"5\",\n",
    "    \"tool_seq_repeat\": \"true\",\n",
    "    \"debug_mode\": \"false\",\n",
    "    \"use_workflow_input\": \"ONE\",\n",
    "    \"use_all_generated_data\": \"NONE\",\n",
    "    \"inputs\": [\n",
    "        # {\n",
    "        #     \"DataClass\": [\n",
    "        #         \"IntColumn\"\n",
    "        #     ],\n",
    "        #     \"StatisticalRelevance\": [\n",
    "        #         \"IndependentVariable\"\n",
    "        #     ],\n",
    "        #     \"APE_label\": [\n",
    "        #         \"PassengerId\"\n",
    "        #     ]\n",
    "        # },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"IntColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"DependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"Survived\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"IntColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"IndependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"Pclass\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"StrColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"IndependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"Name\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"StrColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"IndependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"Sex\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"FloatColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"IndependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"Age\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"IntColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"IndependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"SibSp\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"IntColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"IndependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"Parch\"\n",
    "            ]\n",
    "        },\n",
    "        # {\n",
    "        #     \"DataClass\": [\n",
    "        #         \"StrColumn\"\n",
    "        #     ],\n",
    "        #     \"StatisticalRelevance\": [\n",
    "        #         \"IndependentVariable\"\n",
    "        #     ],\n",
    "        #     \"APE_label\": [\n",
    "        #         \"Ticket\"\n",
    "        #     ]\n",
    "        # },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"FloatColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"IndependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"Fare\"\n",
    "            ]\n",
    "        },\n",
    "        # {\n",
    "        #     \"DataClass\": [\n",
    "        #         \"StrColumn\"\n",
    "        #     ],\n",
    "        #     \"StatisticalRelevance\": [\n",
    "        #         \"IndependentVariable\"\n",
    "        #     ],\n",
    "        #     \"APE_label\": [\n",
    "        #         \"Cabin\"\n",
    "        #     ]\n",
    "        # },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"StrColumn\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"IndependentVariable\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"Embarked\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"DataClass\": [\n",
    "                \"MixedDataFrame\"\n",
    "            ],\n",
    "            \"StatisticalRelevance\": [\n",
    "                \"NoRelevance\"\n",
    "            ],\n",
    "            \"APE_label\": [\n",
    "                \"titanic_train\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"outputs\": [\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_MAPPING = [{\n",
    "    'label': 'titanic_train',\n",
    "    'source': os.path.abspath(os.path.join(\n",
    "        'usecases',\n",
    "        'titanic',\n",
    "        'train.csv',\n",
    "    )),\n",
    "    'type': 'csv',\n",
    "    'DataClass': 'MixedDataFrame',\n",
    "    'StatisticalRelevance': 'NoRelevance'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_min_input = [\n",
    "    # Set 1 Feature Engineering\n",
    "    (\n",
    "        [\n",
    "            { # extract_i\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['extract_i']},\n",
    "                    {'APE_label': ['Name']},\n",
    "                ]\n",
    "            }, {\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['extract_i']},\n",
    "                    {'APE_label': [' ([A-Za-z]+)\\.']},\n",
    "                ]\n",
    "            }, { # replace_re_i\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['replace_re_i']},\n",
    "                    {'APE_label': ['Name']},\n",
    "                ]\n",
    "            }, {\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['replace_re_i']},\n",
    "                    {'APE_label': ['Lady|Countess|Capt|Col|Don|Dr|Major|Rev|Sir|Jonkheer|Dona']},\n",
    "                ]\n",
    "            }, {\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['replace_re_i']},\n",
    "                    {'APE_label': ['Rare']},\n",
    "                ]\n",
    "            }, { # bin_nominal_i\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['bin_nominal_i']},\n",
    "                    {'APE_label': ['Age']},\n",
    "                ]\n",
    "            }, {\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['bin_nominal_i']},\n",
    "                    {'APE_label': ['4']},\n",
    "                ]\n",
    "            }, { # bin_nominal_q_i\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['bin_nominal_q_i']},\n",
    "                    {'APE_label': ['Fare']},\n",
    "                ]\n",
    "            }, {\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['bin_nominal_q_i']},\n",
    "                    {'APE_label': ['4']},\n",
    "                ]\n",
    "            }, { # impute_median_i\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['impute_median_i']},\n",
    "                    {'APE_label': ['Age']},\n",
    "                ]\n",
    "            }, { # impute_mode_i\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['impute_mode_i']},\n",
    "                    {'APE_label': ['Embarked']},\n",
    "                ]\n",
    "            }, { # one_hot_encode_i\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['one_hot_encode_i']},\n",
    "                    {'APE_label': ['Name']},\n",
    "                ]\n",
    "            # }, { # one_hot_encode_i\n",
    "            #     'constraintid': 'operation_input',\n",
    "            #     'parameters': [\n",
    "            #         {'ToolsTaxonomy': ['one_hot_encode_i']},\n",
    "            #         {'APE_label': ['Sex']},\n",
    "            #     ]\n",
    "            # }, { # one_hot_encode_i\n",
    "            #     'constraintid': 'operation_input',\n",
    "            #     'parameters': [\n",
    "            #         {'ToolsTaxonomy': ['one_hot_encode_i']},\n",
    "            #         {'APE_label': ['Embarked']},\n",
    "            #     ]\n",
    "            }, { # iter_2 fix order\n",
    "                'constraintid': 'itn_m',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['Encoding']},\n",
    "                    {'ToolsTaxonomy': ['EDAFeatureEngineering']},\n",
    "                ]\n",
    "            }, {\n",
    "                'constraintid': 'depend_m',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['replace_re_i']},\n",
    "                    {'ToolsTaxonomy': ['extract_i']},\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        # 9, # memout\n",
    "        7,\n",
    "        [\n",
    "            {\n",
    "                \"DataClass\": [\"Str\"],\n",
    "                \"StatisticalRelevance\": [\"BasicObjectRelevance\"],\n",
    "                \"APE_label\": [\" ([A-Za-z]+)\\.\"]\n",
    "            }, {\n",
    "                \"DataClass\": [\"Str\"],\n",
    "                \"StatisticalRelevance\": [\"BasicObjectRelevance\"],\n",
    "                \"APE_label\": [\"Lady|Countess|Capt|Col|Don|Dr|Major|Rev|Sir|Jonkheer|Dona\"]\n",
    "            }, {\n",
    "                \"DataClass\": [\"Str\"],\n",
    "                \"StatisticalRelevance\": [\"BasicObjectRelevance\"],\n",
    "                \"APE_label\": [\"Rare\"]\n",
    "            }, {\n",
    "            #     \"DataClass\": [\"Int\"],\n",
    "            #     \"StatisticalRelevance\": [\"BasicObjectRelevance\"],\n",
    "            #     \"APE_label\": [\"20\"]\n",
    "            # }, {\n",
    "                \"DataClass\": [\"Int\"],\n",
    "                \"StatisticalRelevance\": [\"BasicObjectRelevance\"],\n",
    "                \"APE_label\": [\"4\"]\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "    # Set 2 Modeling\n",
    "    (\n",
    "        [\n",
    "            { # col_split + train_test_split\n",
    "                'constraintid': 'connected_op',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['column_split']},\n",
    "                    {'ToolsTaxonomy': ['train_test_split']},\n",
    "                ]\n",
    "            }, { # fit, required since state is not tracked (no predict without fit)\n",
    "                'constraintid': 'connected_op',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['train_test_split']},\n",
    "                    {'ToolsTaxonomy': ['fit_estimator']}\n",
    "                ]\n",
    "            }, { # use a classifier -> init\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['fit_estimator']},\n",
    "                    {'DataClass': ['Classifier']}\n",
    "                ]\n",
    "            }, { # predict\n",
    "                'constraintid': 'connected_op',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['train_test_split']},\n",
    "                    {'ToolsTaxonomy': ['predict']},\n",
    "                ]\n",
    "            }, { # classification_report, hopefully matches (X_test, y_test)\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['classification_report']},\n",
    "                    {'StatisticalRelevance': ['Prediction']},\n",
    "                ]\n",
    "            }, {\n",
    "                'constraintid': 'connected_op',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['train_test_split']},\n",
    "                    {'ToolsTaxonomy': ['classification_report']},\n",
    "                ]\n",
    "            },\n",
    "        ],\n",
    "        6,\n",
    "        [],\n",
    "    ),\n",
    "    # Set 3 Ensembling\n",
    "    (\n",
    "        [\n",
    "            { # init_sklearn_voting_estimator -> ComplexEnsemble\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['init_sklearn_voting_estimator']},\n",
    "                    {'APE_label': ['RandomForestClassifier,LinearSVClassifier,LogisticRegressionClassifier']},\n",
    "                ]\n",
    "            }, { # col_split + train_test_split\n",
    "                'constraintid': 'connected_op',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['column_split']},\n",
    "                    {'ToolsTaxonomy': ['train_test_split']},\n",
    "                ]\n",
    "            }, { # fit, required since state is not tracked (no predict without fit)\n",
    "                'constraintid': 'connected_op',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['train_test_split']},\n",
    "                    {'ToolsTaxonomy': ['fit_estimator']}\n",
    "                ]\n",
    "            }, { # use a classifier -> VotingClassifier\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['fit_estimator']},\n",
    "                    {'DataClass': ['Classifier']}\n",
    "                ]\n",
    "            }, { # predict\n",
    "                'constraintid': 'connected_op',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['train_test_split']},\n",
    "                    {'ToolsTaxonomy': ['predict']},\n",
    "                ]\n",
    "            }, { # classification_report, hopefully matches (X_test, y_test)\n",
    "                'constraintid': 'operation_input',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['classification_report']},\n",
    "                    {'StatisticalRelevance': ['Prediction']},\n",
    "                ]\n",
    "            }, {\n",
    "                'constraintid': 'connected_op',\n",
    "                'parameters': [\n",
    "                    {'ToolsTaxonomy': ['train_test_split']},\n",
    "                    {'ToolsTaxonomy': ['classification_report']},\n",
    "                ]\n",
    "            },\n",
    "        ],\n",
    "        6,\n",
    "        [\n",
    "            {\n",
    "                \"DataClass\": [\"Str\"],\n",
    "                \"StatisticalRelevance\": [\"BasicObjectRelevance\"],\n",
    "                \"APE_label\": ['RandomForestClassifier,LinearSVClassifier,LogisticRegressionClassifier']\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- embedding / scaling steps are introducing data leakage since they are applied before the train/test split\n",
    "    - no direct way to reference group of operations to be applied again in APE (pipeline step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Iteration 2\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\tWorkflow discovery - length 6\n",
      "-------------------------------------------------------------\n",
      "Total problem setup time: 38.859 sec (6837143 clauses).\n",
      "Found 5 solutions. Solving time: 11.44 sec.\n",
      "\n",
      "\n",
      "APE found 5 solutions.\n",
      "Total APE runtime: \t\t54.83 sec.\n",
      "Total encoding time: \t\t38.859 sec.\n",
      "Total SAT solving time: \t11.44 sec.\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\tGenerating graphical representation\n",
      "\tof the first 5 workflows\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Loading.....\n",
      "\n",
      "Graphical files have been generated. Running time: 0.976 sec.\n",
      "CWL annotations file not configured. No executable CWL files are generated.\n",
      "APE finished 2\n",
      "Notebooks produced 2\n",
      "input_step: 13\n",
      "Iteration 3\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\tWorkflow discovery - length 6\n",
      "-------------------------------------------------------------\n",
      "Total problem setup time: 38.553 sec (7217915 clauses).\n",
      "Found 5 solutions. Solving time: 4.341 sec.\n",
      "\n",
      "\n",
      "APE found 5 solutions.\n",
      "Total APE runtime: \t\t47.53 sec.\n",
      "Total encoding time: \t\t38.553 sec.\n",
      "Total SAT solving time: \t4.341 sec.\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\tGenerating graphical representation\n",
      "\tof the first 5 workflows\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Loading.....\n",
      "\n",
      "Graphical files have been generated. Running time: 0.931 sec.\n",
      "CWL annotations file not configured. No executable CWL files are generated.\n",
      "APE finished 3\n",
      "Notebooks produced 3\n"
     ]
    }
   ],
   "source": [
    "last_len = -1\n",
    "for iter_ix, cst_conf in enumerate(constraint_min_input, start=1):\n",
    "    if last_len >= 0:\n",
    "        input_step += last_len\n",
    "        print(f\"input_step: {input_step}\")\n",
    "    else:\n",
    "        # input_step = 0\n",
    "        input_step = 7\n",
    "\n",
    "    print('Iteration', iter_ix)\n",
    "\n",
    "    if iter_ix == 1:\n",
    "        continue\n",
    "\n",
    "    constraint_set, min_len, inputs = cst_conf\n",
    "\n",
    "    # create config and constraints\n",
    "    with open(USE_CASE_PATH / 'constraints_run.json', 'w', encoding='utf-8') as file_:\n",
    "        json.dump({\"constraints\": constraint_set}, file_, indent=4)\n",
    "\n",
    "    config_local = CONFIG.copy()\n",
    "    config_local['inputs'] += inputs\n",
    "    config_local['solution_length']['min'] = min_len\n",
    "    with open(USE_CASE_PATH / config, 'w', encoding='utf-8') as file_:\n",
    "        json.dump(config_local, file_, indent=4)\n",
    "\n",
    "    # run APE\n",
    "    proc = subprocess.Popen(\n",
    "        ['java', '-Xmx8g', '-jar', str(APE_PATH), config],\n",
    "        cwd=str(USE_CASE_PATH),\n",
    "    )\n",
    "    proc.wait()\n",
    "\n",
    "    # check error code\n",
    "    if proc.returncode != 0:\n",
    "        print('APE failed', iter_ix)\n",
    "        continue\n",
    "    print('APE finished', iter_ix)\n",
    "\n",
    "    # output\n",
    "    folder_path = USE_CASE_PATH / 'out' / f'iteration_{iter_ix}'\n",
    "    folder_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # copy input files into the output folder\n",
    "    shutil.copy(\n",
    "        str(USE_CASE_PATH / config),\n",
    "        str(folder_path / config),\n",
    "    )\n",
    "    shutil.copy(\n",
    "        str(USE_CASE_PATH / 'constraints_run.json'),\n",
    "        str(folder_path / 'constraints_run.json'),\n",
    "    )\n",
    "\n",
    "    # copy solutions\n",
    "    shutil.copy(\n",
    "        str(USE_CASE_PATH / 'solutions' / 'solutions.txt'),\n",
    "        str(folder_path / 'solutions.txt'),\n",
    "    )\n",
    "\n",
    "    shutil.copytree(\n",
    "        str(USE_CASE_PATH / 'solutions' / 'Figures'),\n",
    "        str(folder_path / 'Figures'),\n",
    "        dirs_exist_ok=True,\n",
    "    )\n",
    "\n",
    "    # produce notebooks\n",
    "    workflows_list = parse_ape_solutions(\n",
    "        folder_path / 'solutions.txt',\n",
    "        input_step=input_step,\n",
    "    )\n",
    "\n",
    "    for wk_ix, workflow in enumerate(workflows_list, start=1):\n",
    "        notebook = solution_to_notebook(\n",
    "            workflow,\n",
    "            input_mapping=INPUT_MAPPING,\n",
    "            solution_num=wk_ix-1,\n",
    "            input_step=input_step,\n",
    "        )\n",
    "        with open(\n",
    "            folder_path / f'workflow_{wk_ix}_start_{input_step}.ipynb',\n",
    "            'w',\n",
    "            encoding='utf-8',\n",
    "        ) as out_:\n",
    "            json.dump(notebook, out_, indent=4)\n",
    "    last_len = len(workflows_list[-1]['steps'])\n",
    "    print('Notebooks produced', iter_ix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
